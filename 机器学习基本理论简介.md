**深度学习理论的启示与前瞻**

本次课程不仅对关于数据科学与人工智能的知识技术进行了复盘，更对科学范式以及其未来发展方向进行了深度探讨

# **核心反思：理论与实践的“断裂”与“共生”**

数据科学或人工智能行业的从业者始终面临一个尴尬的事实，即大家都认可深度学习方法的的效力，但其具体运作方式至今仍然是一个“黑箱”，没有人知道它到底为什么能产生如此好的效果。这说明了深度学习仍处于一种原始阶段，也未来其理论的研究方向。

而我们回顾机器学习理论的发展：学习的本质是通过获得多组多维数据x和y来推导出x到y的映射关系f，而得到f的方法即是计算f(x)与y之间的误差并取误差最小的一个f。这样一来，学习问题就被转化成了寻找最小值的问题。传统路径选择使用多项式逼近f，数学理论告诉我们，只要有足够的数据和合适的模型，我们就能逼近任何函数到任意精度。这为学习提供了理论上的“安全感”。但与此同时，多项式逼近也带来了“维数灾难”，使得逼近效率在维数较大时极为低下。

然而，深度学习即神经网络的实践却走上了一条看似“离经叛道”的道路，不再仅仅依赖于多项式逼近这样安全而稳妥的方法。深度学习的方法定义了与多维向量x对应的代表“权重”的多维向量w，根据计算x·w+b与0的大小关系达成“判断”的效果，由此一来便把学习的问题转化为了优化w和b的问题。而这样的优化可以通过一种被数学证明一定收敛的方法——随机梯度下降法—— 来实现。这种转向提供了比多项式逼近更高效的优化方案，打破了“维数灾难”的限制。

# **历史回眸：从“寒冬”到“盛夏”的三次浪潮**

事实上，神经网络的方法早在人工智能兴起的初期就已经被提出，只是当时并没有被采纳。回顾人工智能发展历史，大致有以下两次兴衰：

1. 第一次热潮与寒冬：1957年，Rosenblatt发明感知机，即为单层神经网络。这带来了第一次兴奋，但Minsky指出其无法解决非线性函数，如简单的“亦或”计算，这说明了该模型的表达能力不足，并导致了第一个AI寒冬。此时，理论走到了实践前面，并“证明”了实践的失败。

2. 第二次热潮与困境：多层神经网络和反向传播算法的提出，带来了第二次热潮。“万能逼近定理”证明神经网络可以逼近所有函数，这在理论上赋予了神经网络“无所不能”的潜力。然而，实践很快遇到了新的困难：理论研究者证明，多层神经网络（在特定初始值时）在找损失函数全局极小值困难，复杂的非线性与非凸性使随机梯度下降时容易被局部极小值困住，这说明了此时模型的表达能力未被释放。

3. 第三次热潮与爆发：数据、算力与初始化的胜利。我们正身处第三次浪潮之中。这次的爆发并非源于理论的根本性突破，而是由三大工程性因素驱动：首先是数据：互联网提供了从前难以获取的大规模数据。其次是算力：强大的GPU集群是数据得以被利用。最后是技术技巧：第三次热潮中的算法采用了更优的初始化条件，使得优化不再被局部极小点困住。除此以外，第三次热潮的爆发还离不开在前三者支持下被发现的Scaling law，人民发现给模型提供的数据越多，模型的性能越好，且这种正相关没有边际效益，这样明确无风险的收益吸引到了大量的投资，这才有了ChatGPT的诞生。

# **专题拓展：破解当代深度学习的“未解之谜”**

课程的后半部分，提出了深度学习理论目前的未解之谜以及研究方向。

1.  优化之谜：“为什么神经网络易优化？

神经网络的优化过程类似一个黑箱，我们只知道它能够绕过局部极小点到最小值，却不知道达成这个结果的具体原理。其中一种猜测认为局部极小值可能并非想象中那么多，大部分驻点可能是“鞍点”，而梯度下降法有能力逃离鞍点。另一种猜测认为目标函数没有局部极小点。此外，Meta的研究表明，优化有时仅依赖极少数参数的改变，这样优化过程自然变得更容易。

2. 泛化之谜：“为什么基于有限数据的学习结果能泛化？”

当模型参数数量远超训练样本数时，模型完全有能力“记住”所有数据，而不是学习其规律。根据经典统计学习理论，这必然导致严重的过拟合。但事实是，这些大模型展现出了惊人的泛化能力。有研究者认为优化算法本身具有偏好，它倾向于优先寻找“简单”的解，而不是死记硬背所有的数据，进而获得了泛化能力。随之而来的问题便是：模型为什么会优先学习简单的解？

这指向了奥卡姆剃刀原则在深度学习中的体现。“双下降”现象证明了模型的简约性：研究发现，随模型复杂度增加，泛化误差会先下降后上升，形成U形曲线，而当模型复杂度继续增大，泛化误差会再次下降。U形曲线说明模型首先从欠拟合状态逐渐通过增加参数、提高表达能力达到完全拟合，而后开始收到噪声的干扰，即过拟合，由于“死记硬背”噪声的影响而失去了泛化能力。而随着参数量进一步增大，优化算法在噪声干扰中抽离出普遍真理，优先选择了简单的解释，模型逐渐从僵硬变得灵活。而模型对简单解的偏好可能源于随机梯度下降过程中对“平滑”的偏好：过拟合的解在函数空间中往往是陡峭的，这样在下降的过程中更容易被抛离这一区域。

# **总结**

我们对大模型的工作原理仍处于“盲人摸象”的阶段。未来的研究方向，必将聚焦于破解模型“黑箱”，寻找其理论本质。当这些问题被解开时，我们迎来的将不仅是更高效、更强大的模型，更是人工智能作为一种科学范式的真正成熟。