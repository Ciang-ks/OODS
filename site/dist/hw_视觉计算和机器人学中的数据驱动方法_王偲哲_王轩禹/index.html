<!DOCTYPE html><html lang="zh-CN"> <head><meta charset="UTF-8"><meta name="description" content="OODS Homeworks"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v4.16.19"><title>视觉计算和机器人学中的数据驱动方法</title><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><link rel="stylesheet" href="/OODS/_astro/_slug_.yDLEMZEj.css"><script type="module" src="/OODS/_astro/hoisted.DVZEIXQB.js"></script></head> <body class="bg-white text-slate-900 min-h-screen selection:bg-indigo-100 selection:text-indigo-900"> <header class="bg-[#24292e] text-white top-0 sticky z-50 shadow-sm"> <div class="max-w-4xl mx-auto px-6 h-16 flex items-center justify-between"> <a href="/OODS" class="font-bold text-xl tracking-tight text-white/90 hover:text-white transition-colors flex items-center gap-2"> <svg height="20" viewBox="0 0 24 24" width="20" fill="currentColor" style="opacity: 0.8;"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 18c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8zm-1-13h2v6h-2zm0 8h2v2h-2z"></path></svg>
OODS
</a> <span class="text-xs font-mono text-white/60">Course Works</span> </div> </header> <main class="max-w-4xl mx-auto px-6 py-12">  <article class="max-w-none"> <header class="mb-16 pb-12 border-b border-slate-200 relative -mx-6 px-6 py-16 md:py-24 overflow-hidden" style="background-image: url('/OODS/CV_and_robotic.png'); background-size: cover; background-position: center;"> <div class="absolute inset-0 bg-gradient-to-b from-white/90 via-white/85 to-white/95 backdrop-blur-[2px]"></div> <div class="relative z-10"> <div class="flex flex-wrap items-center gap-3 text-sm mb-6 font-mono"> <span class="uppercase tracking-wider text-xs font-semibold text-slate-600">report</span> </div> <h1 class="text-4xl md:text-5xl font-extrabold mb-8 leading-tight tracking-tight text-balance text-slate-900"> 视觉计算和机器人学中的数据驱动方法 </h1> <div class="flex flex-wrap gap-4"> <div class="flex items-center gap-3 bg-white/90 backdrop-blur-sm pr-4 pl-2 py-2 rounded-full border border-slate-200 shadow-sm"> <div class="w-8 h-8 rounded-full bg-slate-100 flex items-center justify-center text-xs font-bold text-slate-600 border border-slate-200"> 王 </div> <span class="text-base font-medium text-slate-700"> 王偲哲 </span> </div><div class="flex items-center gap-3 bg-white/90 backdrop-blur-sm pr-4 pl-2 py-2 rounded-full border border-slate-200 shadow-sm"> <div class="w-8 h-8 rounded-full bg-slate-100 flex items-center justify-center text-xs font-bold text-slate-600 border border-slate-200"> 王 </div> <span class="text-base font-medium text-slate-700"> 王轩禹 </span> </div> </div> </div> </header> <div class="content-body relative markdown-body" style="background-color: transparent;"> <h2 id="一课程概述">一、课程概述</h2>
<p>本课程由北京大学穆亚东老师主讲，系统介绍了计算机视觉与机器人学中基于数据驱动的方法。内容涵盖从早期的视觉表示理论，到经典的视觉词袋模型，再到以深度学习为代表的现代表示学习方法，最后延伸至生成模型与机器人应用，构建了一个完整的知识体系。</p>
<hr>
<h2 id="二计算机视觉概述与应用场景">二、计算机视觉概述与应用场景</h2>
<ol>
<li>行业应用热度
课程展示了中国计算机视觉在不同行业的投融资热度，排名前三的领域为：
<ul>
<li>零售（64.4%）</li>
<li>安防（50.7%）</li>
<li>制造（47.3%）
其他如政务、医疗、金融等也占有重要比例，显示出计算机视觉技术的广泛应用前景。</li>
</ul>
</li>
<li>典型应用案例
<ul>
<li>人脸识别：北大“刷脸入校”系统，实现无卡通行；</li>
<li>视频监控分析：人体属性识别、行人重识别、人群计数；</li>
<li>图像生成与篡改检测：DeepFake、人脸属性编辑；</li>
<li>自动驾驶：道路识别、速度估计、环境感知；</li>
<li>增强现实：如AR试鞋、Google Goggles等。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="三计算机视觉的基础问题与方法演进">三、计算机视觉的基础问题与方法演进</h2>
<ol>
<li>视觉表示理论（David Marr）
<ul>
<li>原始图像 → 初级草图 → 2.5维草图 → 三维模型</li>
<li>强调从像素到语义的层次化表示过程。</li>
</ul>
</li>
<li>语义鸿沟<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>
<ul>
<li>“语义鸿沟”是针对计算机在识别图像中是否包含某个具体物件上遭遇的问题提出的概念。</li>
<li>计算机所见的低层特征（像素、边缘）与人类理解的高层语义之间存在巨大差异。即对于计算机，从简单的图像特征如像素中提取其表示的“语义特征”(Semantics)是低效率的。</li>
<li>解决方法：引入特征工程与表示学习。</li>
</ul>
</li>
<li>视觉变化与识别粒度
<ul>
<li>影响因素：姿态、光照、尺度等；</li>
<li>识别任务从粗粒度（是否存在物体）到细粒度（如不同种类的杜鹃鸟）。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="四经典方法视觉词袋模型">四、经典方法：视觉词袋模型</h2>
<ol>
<li>基本思想
“词袋模型”源于文本处理领域，即通过不考虑语法和顺序特征，仅考虑文本中词语的集合，视觉处理中借用这一方法提出“视觉词袋模型”<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>（Bag-of-Visual-Words, BoVW），核心为将图像视为一系列局部特征的集合，忽略空间关系，构建视觉词典。
<ul>
<li><strong>局部特征集合</strong>：图像不再被视为像素矩阵，而是被分解为一系列独立的小块。</li>
<li><strong>忽略空间关系</strong>：模型在构建特征时，故意忽略这些局部特征在图像中的空间位置关系。</li>
<li><strong>构建视觉词典</strong>：通过对大量局部特征进行聚类，将相似的特征归为一类，形成一个视觉词典。</li>
</ul>
</li>
<li>流程步骤
$\text{BoVW}$ 模型通常遵循以下四个主要步骤：</li>
</ol>



































<table><thead><tr><th align="left">步骤</th><th align="left">核心任务</th><th align="left">具体技术（示例）</th><th></th></tr></thead><tbody><tr><td align="left"><strong>检测关键点</strong></td><td align="left">识别图像中具有辨识度、对变换稳定的点。</td><td align="left"><strong>Harris</strong> 角点（见【3】）、SIFT/SURF 关键点。</td><td></td></tr><tr><td align="left"><strong>提取局部特征</strong></td><td align="left">对关键点周围的区域进行量化描述，生成描述符。</td><td align="left"><strong>SIFT</strong> (尺度不变特征变换) 是最常用的描述符。</td><td></td></tr><tr><td align="left"><strong>聚类构建视觉词典</strong></td><td align="left">将所有训练图像的局部特征进行聚类。</td><td align="left"><strong>K-means</strong> 聚类算法最常用。聚类中心即为“视觉词”。</td><td></td></tr><tr><td align="left"><strong>量化特征</strong></td><td align="left">将每个局部特征分配到最近的视觉词典中心。</td><td align="left">生成图像直方图：统计图像中每个“视觉词”出现的次数，形成最终的图像表示向量。</td><td></td></tr></tbody></table>
<ol start="3">
<li>Harris角点检测<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup>
Harris角点检测是检测关键点的方法之一，它通过分析图像窗口在不同方向上移动时的灰度变化量来识别角点。 该方法的核心是使用图像窗口的变化量以及由特征值 $(\lambda_1, \lambda_2)$ 构成的矩阵来判断区域类型：</li>
</ol>



































<table><thead><tr><th align="left">区域类型</th><th align="left">特征值 $(\lambda_1, \lambda_2)$ 条件</th><th align="left">几何解释</th><th></th></tr></thead><tbody><tr><td align="left"><strong>平坦区域</strong></td><td align="left">$\lambda_1$ 和 $\lambda_2$ 都很小。</td><td align="left">窗口在任何方向上移动，灰度变化都不明显。</td><td></td></tr><tr><td align="left"><strong>边缘</strong></td><td align="left">一个特征值远大于另一个。</td><td align="left">窗口沿着边缘方向移动时灰度变化小，垂直于边缘方向移动时灰度变化大。</td><td></td></tr><tr><td align="left"><strong>角点</strong></td><td align="left">$\lambda_1$ 和 $\lambda_2$ 都大且相近。</td><td align="left">窗口在所有方向上移动，灰度变化都很显著。</td><td></td></tr><tr><td align="left"></td><td align="left"></td><td align="left"></td><td></td></tr></tbody></table>
<hr>
<h2 id="五数据驱动方法的兴起">五、数据驱动方法的兴起</h2>
<ol>
<li>从传统机器学习到深度学习
<ul>
<li>传统方法：手工设计特征 + 分类器（如SVM）；</li>
<li>深度学习：端到端学习，自动提取多层次特征。</li>
</ul>
</li>
<li>表示学习
<ul>
<li>特征提取与模型训练融为一体；</li>
<li>层次化表示：低层 → 中层 → 高层特征。</li>
</ul>
</li>
<li>里程碑：ImageNet与AlexNet</li>
</ol>
<ul>
<li>ImageNet：大规模图像数据集，推动视觉识别竞赛（ILSVRC）；</li>
<li>AlexNet：首次展示深度卷积网络的强大能力，开启深度学习时代。</li>
</ul>
<hr>
<h2 id="六深度学习与神经网络">六、深度学习与神经网络</h2>
<ol>
<li>
<p>网络结构演进</p>
<ul>
<li>LeNet-5 → AlexNet → VGG → GoogleNet → ResNet
<ul>
<li><strong>VGG</strong>：该网络通过堆叠小尺寸的 $3 \times 3$ 卷积核来加深网络层级，其设计哲学是<strong>模块化</strong>和<strong>深度优先</strong>。使用堆叠多个小卷积核来替代一个大卷积核，用增加的卷积次数来获得更多的非线性变化同时使用更少的参数量。</li>
<li><strong>GoogleNet</strong>：引入 <strong>Inception 模块</strong><sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup>，通过并行处理不同尺度的卷积核和 $1 \times 1$ 卷积降维，在保证性能的同时显著降低了参数量和计算复杂度。先通过 $1 \times 1$ 卷积进行降维可以在不改变图像尺寸的情况下降低后续大卷积核的计算负担。</li>
<li><strong>ResNet</strong>：该网络引入了<strong>残差连接</strong>（Residual Connection）<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>。这一结构允许信息直接跨层传递，有效解决了超深网络的梯度消失<sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup>和网络退化问题，是深度学习发展史上的关键一步。ResNet中的残差连接算法通过学习残差而非恒等映射，避免了梯度在学习过程中发生损失。</li>
</ul>
</li>
<li>网络层数不断增加，错误率持续下降。</li>
</ul>
</li>
<li>
<p>核心机制：梯度、链式法则与反向传播</p>
<p>网络的训练核心是<strong>反向传播</strong>（Back Propagation）算法，其目的是实现基于<strong>梯度下降</strong>的参数更新。</p>
<p><strong>梯度</strong>是训练优化的关键，它表示损失函数相对于网络参数（权重和偏置）的变化率，指明了损失函数值增加最快的方向。通过沿着梯度的负方向进行调整，网络参数可以被优化以最小化损失。</p>
<p>反向传播利用<strong>链式法则</strong>（Chain Rule）这一数学工具。链式法则允许我们将对整个复合函数（即整个网络）的求导分解为对每个局部函数（即每一层神经元）的求导，并将结果逐层传递相乘。</p>
<p>该过程分为前向和后向两个阶段：在前向传播中，数据从输入层流向输出层，计算最终的损失值。在关键的后向传播阶段，算法从输出层的损失开始，利用链式法则逐层向输入层逆向进行，精确计算出损失函数对每一层权重参数的梯度。最终，优化器根据计算出的梯度来调整网络权重，完成参数更新。</p>
</li>
</ol>
<hr>
<h2 id="七生成模型从判别到生成">七、生成模型：从判别到生成</h2>
<ol>
<li>生成模型类型
<ul>
<li>自编码器：编码-解码结构，用于特征学习与重建；</li>
<li>变分自编码器：引入隐变量分布，增强生成多样性；</li>
<li>生成对抗网络：判别器与生成器对抗训练；</li>
<li>扩散模型：通过逐步加噪与去噪实现图像生成。</li>
</ul>
</li>
<li>应用场景
<ul>
<li>图像生成、风格迁移、DeepFake检测、艺术创作等。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="八机器人学与视觉的结合">八、机器人学与视觉的结合</h2>
<ul>
<li>
<p>案例：OpenAI使用机器人手解魔方；[<a href="https://openai.com/blog/solving-rubiks-cube/">https://openai.com/blog/solving-rubiks-cube/</a>]</p>
</li>
<li>
<p>强调视觉感知在机器人控制、路径规划、环境交互中的关键作用。</p>
</li>
<li>
<p>然而，相比于视觉识别和环境感知等相对成熟的领域，机器人在完成现实中的任务时仍存在许多困难。</p>
<p>其原因可归结为，现实操作任务涉及高维度的动作空间、复杂的物理交互以及对长时程规划的依赖，这些因素在传统的视觉识别任务中并不存在。首先，维度上的巨大差异构成了首要障碍。视觉识别通常处理 $2D$ 图像或 $3D$ 几何数据，输出是一个低维度的信息标签（如物体类别或位置），而机器人操作必须控制高维度的连续动作序列，例如一个七自由度机械臂的关节角度或末端执行器的六自由度姿态 $\left(x, y, z, r_x, r_y, r_z\right)$。这使得机器人的动作空间呈指数级增长，导致数据稀疏性，即通过有限的训练数据难以覆盖所有可能的动作和环境变化。</p>
<p>其次，机器人必须处理复杂的物理世界，尤其涉及非刚体操作。视觉感知领域主要处理刚体（如杯子、汽车），但家庭任务中常见的布料、食物或液体等非刚体，其状态是连续变化的，需要实时理解和预测摩擦力、重力和弹性等物理属性。这要求机器人不仅要“看到”物体，还要“理解”作用于物体上的力学机制，目前的大多数数据驱动模型缺乏这种物理先验知识。</p>
<p>此外，缺乏高分辨率的触觉反馈也是一个关键限制。人类在叠衣服时依赖对布料的抓取力度和滑动感的感知，而现有的机器人视觉往往是“远距离”的，难以获取操作所需的近距离、高精度的接触信息。最后，任务的长时程规划与语义分解要求极高。视觉识别多是单步决策（一张图对应一个结果），而现实任务如叠衣服是一个需要多个子步骤、分层级执行的长时程任务。它要求机器人具备高层规划能力（如将“叠衬衫”分解为“对齐衣领”→“折叠袖子”→“二次对折”），以及在执行过程中对子目标状态进行实时检查和纠错的能力。将人类的自然语言指令转化为机器可执行的低层控制信号，中间的语义鸿沟巨大。</p>
</li>
<li>
<p>解决目前困难的方法与未来发展方向
融合物理先验与触觉感知： 核心在于建立能够将物理模型与深度学习相结合的可微分物理引擎，使其能够实时预测非刚体的变形。同时，大力发展高精度的触觉传感器和力/扭矩传感器，将触觉数据作为与视觉同等重要的多模态输入，提升机器人对操作精度的控制。</p>
<p>高效的具身数据生成与泛化： 由于真实世界数据采集成本高昂，必须依赖高保真度的仿真环境高效生成海量训练数据。同时，结合模仿学习快速从人类演示中学习复杂技能，并通过离线强化学习、充分利用已有的交互数据，以提高模型在未知环境下的泛化能力。</p>
</li>
</ul>
<hr>
<h2 id="九课程建议与学习路径">九、课程建议与学习路径</h2>
<ol>
<li>知识结构建议
<ul>
<li>数学基础：数学分析、线性代数、最优化、凸优化；</li>
<li>计算机基础：数据结构、算法、系统课程；</li>
<li>机器学习：导论、深度学习、强化学习；</li>
<li>视觉与机器人：计算机视觉、图像处理、3D视觉、控制论。</li>
</ul>
</li>
<li>学习建议
<ul>
<li>“AI is electricity”：认识其双面性；</li>
<li>尽早接触前沿课题，培养科研嗅觉；</li>
<li>重视工程实现能力，理论与实践并重。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="十总结">十、总结</h2>
<p>本课程系统性地梳理了计算机视觉与机器人学中的数据驱动方法，从传统视觉词袋模型到现代深度学习与生成模型，展现了技术演进的脉络。课程不仅覆盖理论基础与核心技术，还强调实际应用与伦理思考，为学习者构建了完整的知识体系与研究视角。</p>
<hr>
<h2 id="ai协作记录">AI协作记录</h2>
<div style="font-size: small;">
<p><strong>Prompt 1:</strong>
基于数据驱动方法的视觉识别已经发展到一定高度了，但机器人学中完成具体现实任务如叠衣服仍然存在很大的困难，这种隔阂主要由何引起，以及需要在什么方面继续发展才能让机器完成更加贴近人类生活中的任务？</p>
<p><strong>Answer:</strong>
Google Gemini:
您提出的问题非常深刻，它指出了当前**数据驱动的视觉识别（Vision）<strong>和</strong>现实世界机器人操作（Robotics）**之间存在的关键“隔阂”（Gap）。</p>
<p>这种隔阂主要源于以下几个核心差异和挑战：</p>
<hr>
<h2 id="隔阂的主要根源-core-sources-of-the-gap">隔阂的主要根源 (Core Sources of the Gap)</h2>
<p>视觉识别（如图像分类、目标检测、分割）在理想的数据集上表现出色，但机器人操作涉及更复杂、更高维度的现实世界交互。</p>
<h3 id="1-维度和复杂性的差异-dimensionality-and-complexity">1. 维度和复杂性的差异 (Dimensionality and Complexity)</h3>
<ul>
<li><strong>视觉识别 (Vision):</strong> 主要处理 $2D$ 或 $3D$ 静态/动态图像数据，输出是<strong>信息标签</strong>（如目标类别、边界框）。</li>
<li><strong>机器人操作 (Robotics):</strong> 涉及 $6D$ 甚至更高维度的<strong>控制空间</strong>（如机械臂关节角度、末端执行器姿态 $\left(x, y, z, r_x, r_y, r_z\right)$），输出是<strong>连续的动作序列</strong>。任务如叠衣服是<strong>非刚体操作</strong>，需要实时感知和规划布料的连续变形。</li>
</ul>
<h3 id="2-泛化能力和数据稀疏性-generalization-and-data-scarcity">2. 泛化能力和数据稀疏性 (Generalization and Data Scarcity)</h3>
<ul>
<li><strong>视觉识别:</strong> 依赖海量、多样化的、<strong>静态</strong>标注数据（如 ImageNet），任务目标固定。</li>
<li><strong>机器人操作:</strong>
<ul>
<li><strong>高维动作空间:</strong> 现实世界的机器人操作数据收集成本极高，动作空间巨大，导致数据<strong>高度稀疏</strong>，难以覆盖所有可能性。</li>
<li><strong>泛化困难:</strong> 在实验室环境中训练的模型，难以泛化到光照、背景、物体材质略有变化的现实家庭环境。</li>
</ul>
</li>
</ul>
<h3 id="3-具身智能和物理交互-embodied-intelligence-and-physics">3. 具身智能和物理交互 (Embodied Intelligence and Physics)</h3>
<ul>
<li><strong>视觉识别:</strong> 缺乏“身体”（Embodiment），不涉及物理世界的力、摩擦、惯性等。</li>
<li><strong>机器人操作:</strong> 是<strong>具身智能</strong>的核心，必须理解和预测<strong>物理世界</strong>的动态。例如，叠衣服需要判断施加多大的力才能抓起布料而不使其滑落，以及预测布料在重力下的自然下垂和折叠效果。</li>
</ul>
<h3 id="4-任务层次和时间序列-task-hierarchy-and-temporal-sequencing">4. 任务层次和时间序列 (Task Hierarchy and Temporal Sequencing)</h3>
<ul>
<li><strong>视觉识别:</strong> 多数是<strong>单步决策</strong>（一张图对应一个标签）。</li>
<li><strong>机器人操作:</strong> 任务如叠衣服是复杂的<strong>多步骤、长时程、有层次结构</strong>的任务。它要求机器人：
<ol>
<li><strong>高层规划:</strong> 识别布料类型 -> 确定折叠策略。</li>
<li><strong>中层执行:</strong> 抓住一个角 -> 移动到另一个角。</li>
<li><strong>低层控制:</strong> 实时调整抓取力度和轨迹。</li>
</ol>
</li>
</ul>
<hr>
<h2 id="未来发展的方向-future-development-directions">未来发展的方向 (Future Development Directions)</h2>
<p>要弥合这一隔阂，让机器能完成更贴近人类生活的任务（如叠衣服、做饭），需要在以下几个方面重点发展：</p>
<h3 id="1-物理感知和非刚体操作-physics-and-non-rigid-manipulation">1. 物理感知和非刚体操作 (Physics and Non-rigid Manipulation)</h3>
<ul>
<li><strong>核心挑战:</strong> 建立能<strong>实时建模和预测</strong>非刚体（如布料、面团）物理状态变化的系统。</li>
<li><strong>发展方向:</strong>
<ul>
<li><strong>物理先验的融合:</strong> 将物理引擎、有限元分析（FEA）等<strong>物理模型</strong>融入深度学习框架，指导动作规划。</li>
<li><strong>Tacktile Sensing (触觉感知):</strong> 发展高分辨率、高鲁棒性的<strong>触觉传感器</strong>  和相应的触觉反馈控制，让机器人能“感受”布料的滑动、褶皱和应力。</li>
</ul>
</li>
</ul>
<h3 id="2-高效的具身数据生成和泛化-efficient-embodied-data-and-generalization">2. 高效的具身数据生成和泛化 (Efficient Embodied Data and Generalization)</h3>
<ul>
<li><strong>核心挑战:</strong> 解决现实世界数据稀疏和泛化差的问题。</li>
<li><strong>发展方向:</strong>
<ul>
<li><strong>Sim-to-Real (从仿真到现实):</strong> 大力发展<strong>高保真度</strong>的物理仿真环境（如 Isaac Gym, MuJoCo, PyBullet），在虚拟世界中高效生成海量数据，并发展技术弥补<strong>域转移</strong>（Domain Gap）。</li>
<li><strong>示教学习与模仿学习 (Imitation Learning, IL):</strong> 通过人类演示（Human Demonstration）快速教授复杂技能，并结合<strong>强化学习 (RL)</strong> 进行微调和优化，以提高泛化性。</li>
<li><strong>自监督/无监督学习:</strong> 利用机器人自身与环境的交互（如随机抓取）来学习有用的表征，减少对昂贵人工标注的依赖。</li>
</ul>
</li>
</ul>
<h3 id="3-多模态和高层语义理解-multimodality-and-high-level-semantics">3. 多模态和高层语义理解 (Multimodality and High-Level Semantics)</h3>
<ul>
<li><strong>核心挑战:</strong> 将低级的视觉像素和高级的任务目标联系起来。</li>
<li><strong>发展方向:</strong>
<ul>
<li><strong>语言作为接口 (Language as Interface):</strong> 利用<strong>大语言模型 (LLMs)</strong> 的强大语义和常识推理能力，将人类的自然语言指令（如“把衬衫叠好”）分解成机器人可执行的低级子任务序列。</li>
<li><strong>多模态融合:</strong> 不仅仅依赖视觉，还要融合触觉、力觉、听觉等多模态输入，形成对物体状态的<strong>全面感知</strong>。</li>
</ul>
</li>
</ul>
<h3 id="4-任务分解和长时序规划-task-decomposition-and-long-horizon-planning">4. 任务分解和长时序规划 (Task Decomposition and Long-Horizon Planning)</h3>
<ul>
<li><strong>核心挑战:</strong> 如何将一个复杂任务（如叠衣服）拆解成一系列可控、可检查的子目标。</li>
<li><strong>发展方向:</strong>
<ul>
<li><strong>分层强化学习 (Hierarchical RL, HRL):</strong>  机器人需要一个高层策略器来规划“折叠左半部分”或“对齐衣领”等子目标，以及一个低层控制器来执行具体的动作（关节扭矩）。</li>
<li><strong>基于模型规划 (Model-Based Planning):</strong> 学习一个世界模型来预测动作的后果，从而在执行动作之前进行“试错”和规划，尤其适用于任务失败成本高的现实世界。</li>
</ul>
</li>
</ul>
<p>通过上述方向的持续发展，特别是将<strong>物理感知、高效数据生成、触觉反馈</strong>以及<strong>大模型驱动的语义理解</strong>结合起来，机器人将能够更有效地应对非刚体操作和复杂的家庭任务挑战。</p>
<hr>
<p><strong>Prompt 2:</strong>
基于数据驱动方法的视觉识别已经发展到一定高度了，但机器人学中完成具体现实任务如叠衣服仍然存在很大的困难，这种隔阂主要由何引起，以及需要在什么方面继续发展才能让机器完成更加贴近人类生活中的任务？</p>
<p><strong>Answer:</strong>
Google Gemini:</p>
<p>您提出的问题涉及深度学习优化中的两个核心挑战：<strong>梯度消失/爆炸</strong>和<strong>网络退化</strong>，以及 ResNet 如何巧妙地通过残差连接（Residual Connection）来克服它们。</p>
<p>我将详细解释这些概念及其解决机制。</p>
<h2 id="一超深网络面临的核心问题">一、超深网络面临的核心问题</h2>
<p>在深度学习中，网络的“深”意味着有更多的层次来提取更抽象的特征，但这也带来了两个主要的优化障碍：</p>
<h3 id="1-梯度消失与爆炸-vanishing-and-exploding-gradients">1. 梯度消失与爆炸 (Vanishing and Exploding Gradients)</h3>
<p>这是由<strong>反向传播</strong>（Back Propagation）机制导致的经典问题。</p>
<ul>
<li><strong>机制原理：</strong> 在反向传播过程中，用于更新网络权重（参数）的<strong>梯度</strong>（可以理解为对损失函数的敏感度）是从输出层开始，通过<strong>链式法则</strong>逐层向前计算的。每一层的梯度计算都需要乘以该层之前的<strong>权重矩阵</strong>的导数。</li>
<li><strong>问题产生：</strong>
<ul>
<li><strong>梯度消失：</strong> 当网络中的权重值（或其导数）大部分都很小（例如小于 $1.0$）时，随着层数不断向前（向输入层）传递，这些小数会连续相乘，导致梯度呈<strong>指数级衰减</strong>，变得<strong>极其微小</strong>。
<ul>
<li><strong>结果：</strong> 靠近输入层的网络层（负责提取基础特征，如边缘）几乎接收不到任何有意义的梯度信号。它们的权重无法被更新，学习过程停滞。</li>
</ul>
</li>
<li><strong>梯度爆炸：</strong> 相反，如果权重值大部分都很大（例如大于 $1.0$），梯度会随着前传而<strong>指数级增大</strong>，变得<strong>极其巨大</strong>。
<ul>
<li><strong>结果：</strong> 权重更新幅度过大，导致网络参数瞬间跳到完全不合理的值，使模型发散（即 $\text{Loss}$ 变为 $\text{NaN}$ 或无穷大）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>通俗比喻：</strong> 梯度就像一个信号，需要从终点（输出层）传到起点（输入层）。梯度消失就像信号在长距离传输中，每经过一站就被微弱地衰减一次，传到起点时信号已听不清；梯度爆炸就像每经过一站信号都被放大，传到起点时已震耳欲聋。</p>
</blockquote>
<h3 id="2-网络退化-degradation-problem">2. 网络退化 (Degradation Problem)</h3>
<p>这是一个比梯度消失更微妙、更实际的问题，是 ResNet 诞生的直接驱动力。</p>
<ul>
<li><strong>机制原理：</strong> 理论上，增加网络深度应该能提升性能（至少不会变差），因为你可以随时通过恒等映射（Identity Mapping，即不做任何处理）将多余的层视为无效层。</li>
<li><strong>问题产生：</strong> 在实际训练中，研究发现，当网络层数增加到一定程度（如超过 $20$ 层）时，训练集的<strong>错误率反而开始上升</strong>。
<ul>
<li><strong>原因：</strong> 这并非由<strong>过拟合</strong>（Overfitting）导致，因为这是在训练集上发生的。根本原因在于，即使理论上存在一个恒等映射 $H(x)=x$，但传统的优化算法（如梯度下降）<strong>极难</strong>将堆叠的非线性层训练成一个完美的恒等映射。额外的层反而会<strong>破坏</strong>特征表示的质量。</li>
</ul>
</li>
<li><strong>结果：</strong> 随着网络变深，性能<strong>退化</strong>，更深的网络比同等的浅层网络表现更差。</li>
</ul>
<hr>
<h2 id="二resnet-与残差连接的解决之道">二、ResNet 与残差连接的解决之道</h2>
<p><strong>残差网络 (ResNet)</strong> 由 Kaiming He 等人于 2015 年提出，通过引入<strong>残差连接 (Residual Connection)</strong>，同时解决了上述两个优化难题。</p>
<h3 id="核心机制残差块residual-block">核心机制：残差块（Residual Block）</h3>
<p>ResNet 的基础是<strong>残差块</strong>。它不是让堆叠的层（例如 $L$ 层）去学习一个目标映射 $H(x)$，而是让它们去学习一个<strong>残差映射 $F(x)$</strong>。</p>
<ul>
<li><strong>映射目标转换：</strong>
<ul>
<li><strong>传统网络：</strong> 目标输出 $H(x)$，即 $H(x) = \text{多层非线性变换}(x)$。</li>
<li><strong>残差网络：</strong> 目标输出 $H(x) = F(x) + x$。这里的 $x$ 是输入，而 $F(x)$ 就是残差，即 $F(x) = H(x) - x$。</li>
</ul>
</li>
<li><strong>结构实现：</strong> 在残差块中，输入 $x$ 通过一个**跳跃连接（Skip Connection）**直接加到几层变换后的输出上。</li>
</ul>
<h3 id="1-如何解决网络退化">1. 如何解决网络退化？</h3>
<p>残差连接从根本上解决了<strong>优化恒等映射</strong>的困难。</p>
<ul>
<li><strong>优化简化：</strong> 如果我们想让新增加的几层（即 $F(x)$）不影响网络性能（理想状态是恒等映射 $H(x)=x$），那么优化器只需要将 $F(x)$ 的权重优化到<strong>趋近于零</strong>即可（$F(x) \approx 0$）。</li>
<li><strong>学习难度降低：</strong> 学习<strong>残差 $F(x) \approx 0$</strong> 比让多层非线性网络去学习<strong>恒等映射 $H(x)=x$</strong> 要容易得多。</li>
<li><strong>保证性能：</strong> 即使新加的层没有太多可学之处，残差连接也确保了信息 $x$ 可以<strong>无损地</strong>跳过这些层，避免了特征信息的退化。这就像给信息提供了一条“高速公路”，保证其能畅通无阻地向前传播。</li>
</ul>
<h3 id="2-如何缓解梯度消失">2. 如何缓解梯度消失？</h3>
<p>残差连接的<strong>跳跃路径</strong>为梯度的传播提供了一条<strong>直接且畅通</strong>的路径，有效缓解了梯度消失。</p>
<ul>
<li><strong>梯度直传：</strong> 当进行反向传播时，由于 $H(x) = F(x) + x$，根据求导的线性性质，对 $x$ 求导的结果中会包含一个** $+1$ 项**。
$$\frac{\partial \text{Loss}}{\partial x} = \frac{\partial \text{Loss}}{\partial H(x)} \cdot \left( \frac{\partial F(x)}{\partial x} + \frac{\partial x}{\partial x} \right) = \frac{\partial \text{Loss}}{\partial H(x)} \cdot \left( \frac{\partial F(x)}{\partial x} + 1 \right)$$</li>
<li><strong>$+1$ 项的意义：</strong> 这个 $+1$ 项确保了即使 $F(x)$ 的梯度项 $\frac{\partial F(x)}{\partial x}$ 由于网络太深而变得极小（趋近于 $0$），<strong>总梯度也不会完全消失</strong>，因为至少有 $1$ 这个常数项在保障梯度的传输。</li>
<li><strong>结果：</strong> 梯度信号可以沿着跳跃连接这条“直线”路径，有效地传回网络深层，从而使得靠近输入层的权重也能得到更新，网络得以训练到极深的层次（$152$ 层甚至 $1000$ 层）。</li>
</ul>
<p><strong>总结：</strong> 残差连接通过改变网络的<strong>映射目标</strong>（从学习 $H(x)$ 到学习 $F(x)$），巧妙地将优化问题转化为更简单的<strong>拟合残差</strong>问题，并通过<strong>跳跃连接</strong>提供了梯度回传的保障，从而开启了深度学习的“千层”时代。</p>
</div>
<section data-footnotes="" class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes</h2>
<ol>
<li id="user-content-fn-1">
<p><a href="https://en.wikipedia.org/wiki/Semantic_gap">https://en.wikipedia.org/wiki/Semantic_gap</a> <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-2">
<p><a href="https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision">https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision</a> <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-3">
<p><a href="https://en.wikipedia.org/wiki/Harris_corner_detector">https://en.wikipedia.org/wiki/Harris_corner_detector</a> <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 3" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-4">
<p><a href="https://en.wikipedia.org/wiki/Inception_(deep_learning_architecture)%5C">https://en.wikipedia.org/wiki/Inception_(deep_learning_architecture)\</a> <a href="#user-content-fnref-4" data-footnote-backref="" aria-label="Back to reference 4" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-5">
<p><a href="https://medium.com/data-science/what-is-residual-connection-efb07cab0d55">https://medium.com/data-science/what-is-residual-connection-efb07cab0d55</a> <a href="#user-content-fnref-5" data-footnote-backref="" aria-label="Back to reference 5" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-6">
<p><a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">https://en.wikipedia.org/wiki/Vanishing_gradient_problem</a> <a href="#user-content-fnref-6" data-footnote-backref="" aria-label="Back to reference 6" class="data-footnote-backref">↩</a></p>
</li>
</ol>
</section> </div> </article>   </main> <footer class="border-t border-slate-200 mt-20 py-12 text-center text-slate-500 text-sm"> <p>
&copy; 2026 OODS. All rights reserved.
</p> </footer> </body></html>