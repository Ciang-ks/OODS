**优化相关内容拓展**

课程伊始，老师指出了多分类问题与回归问题的本质区别。在多元分类中，我们不能再简单地将类别编号视为回归目标，因为这样做隐含地假设了类别之间存在数值关系，例如类别1与类别2的"距离"比类别1与类别3更近，这在大多数实际分类问题中并不成立。

为解决这一问题，课程引入了One-hot编码表示法。对于有K个类别的问题，我们将每个标签表示为一个K维向量，其中正确类别位置为1，其余为0。例如，三个类别中的第二类可表示为\[0, 1,0\]。这种表示方法消除了类别间的虚假数值关系，使所有类别在表示空间中都处于平等地位。

为了将模型输出转化为有效的概率分布，课程讲解了Softmax函数。Softmax通过指数变换与归一化操作，将原始的得分向量转换为概率分布，这一过程不仅确保了输出值在0到1之间且和为1，还具有放大数值差异的效果。

在损失函数方面，课程先后讲述了均方误差与交叉熵损失在分类问题中的表现。相较于均方误差，交叉熵与误差成指数关系更加灵敏，并且和Softmax函数一脉相承。交叉熵损失在数学上等价于最大似然估计，能够提供更有效的梯度信号，特别是在预测概率与真实标签相差较大时。

课程深入探讨了优化过程中的多个关键挑战。其一是局部最小值与鞍点问题。解决局部最小值问题可以采用随机梯度下降与小批量梯度下降的方法。随机梯度下降与每次仅使用一个数据计算梯度，这个梯度是全数据梯度的有噪声估计。一方面，它能避免像梯度下降落入局部最小点的困境，采用带有噪声的估计，更容易达到全局的最小点。而另一方面，它每次计算只用一个数据，每个样本都经历一次更新，更新速率快，且对内存更友好。同时还有一种折中的方法即小批量梯度下降，它每次更新采取小批量的数据，这种做法既包含了上述随机梯度下降的优势，又减小了噪声，结果更加稳定。

在高维非凸优化问题中，真正的局部最小值相对少见，更常见的是鞍点，某些方向是上坡，某些方向是下坡这些点会显著减慢学习过程，甚至使训练停滞不前。解决这个问题可以采用动量法，利用先前累计的梯度“惯性”来避免优化在鞍点停滞。也可以采用二阶优化法，通过黑塞矩阵计算曲率，从而判断出优化位置是否在鞍点，从而寻找到梯度下降最有效的方向。在鞍点处，它可以识别负曲率方向来下降。

其二是维数灾难问题。例如对于一张256\*256的照片用RGB表示，其维数就至少是3\*256\*256。维数的增加会导致训练样本在特征空间下的密度指数级下降。如果可用的训练样本数量是固定的，那么如果增加特征维度的话，容易导致分类器维数高，放大并吸纳了过量噪声和异常，结果最终的拟合效果很差，过拟合就会发生。也就是说，如果增加特征维度，为了覆盖同样的特征值范围、防止过拟合，那么所需的训练样本数量就会成指数型增长。

因此我们考虑采取措施降低数据维度。可以采取特征选择算法。如果有N个特征，我们可以选取M个特征作为代表。选取方法一是在曲线中找到性能最佳的位置。但是，由于很难对所有的特征组合进行训练和测试，所以有一些其他办法来找到最佳选择。这些方法称之为**特征选择**算法，经常用启发式方法（例如贪心算法、best-first方法等）来定位最佳的特征组合和数量。

还有一种方法是用M个特征替换N个特征，M个特征由原始特征组合而成。这种通过对原始特征进行优化的线性或非线性组合来减少问题维度的算法称为**特征提取**。一个著名的维度降低技术是主成分分析法（PCA），它去除不相关维度，对N个原始特征进行线性组合。PCA算法试着找到低维的线性子空间，保持原始数据的最大方差。_（以上两段来自知乎《利用降维方法t-SNE解决维数灾难的一些方法》）_

_注：第六段使用了AI来解答鞍点问题的解决方案。_

**感想**

通过本次课程，我首次了解了优化的概念以及优化问题在AI大模型训练中的重要地位。优化“最大程度利用有限资源解决问题”的概念在生活中无处不在，而在AI模型训练领域，则主要表现为如何在有限训练成本下使模型预测更加准确。对于深度学习的基础——多分类模型，如何不断修正打分矩阵X，再利用损失函数(如交叉熵)衡量预测结果与真实结果的差距，进而使X的预测准确度不断上升，这就是优化问题。训练神经网络模型的过程也就是找到其参数的过程，而通过引入优化的概念，可以将将深度学习问题写成简洁的优化问题形式，进而通过设计优化算法来提高模型的性能和训练效率。我了解到大模型训练不仅仅是单纯增加参数量、数据量，更能通过优化问题的巧妙解决“事半功倍”。当然，大模型优化也存在一些困难，目标函数非凸使得优化方法必须被仔细设计，避免被优化进入局部最优解而非全局最优解；同时变量维度的上升使算力开销急剧增大。

当然，除了模型训练中的优化问题，老师还介绍了大模型训练的一般流程，包括预训练、有监督微调、回馈训练(奖励训练)、强化学习等环节。从2022年底GPT“横空出世”以来，AI大模型实现了跨越式的大发展。中国AI的发展也突破了最初不被看好的阴霾：deepseek的诞生证明了在算法侧的精细设计能够冲破算力与数据的限制，达到与GPT接近的水平。当下，可以说全球AI格局是中美占主导地位。中国AI技术发展前景广阔，大有可为。

不过大模型发展也面临“数据瓶颈”等挑战——有人认为大模型消耗数据速度超过人类产生数据的速度。为此，大模型通过具身智能、AI4S自己产生数据，“自产自销”不失为一种解决办法，尤其是在具身智能等应用场景方兴未艾，亟待探索开发的当下。