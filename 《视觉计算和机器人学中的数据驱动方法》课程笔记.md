## 一、课程概述

本课程由北京大学穆亚东老师主讲，系统介绍了计算机视觉与机器人学中基于数据驱动的方法。内容涵盖从早期的视觉表示理论，到经典的视觉词袋模型，再到以深度学习为代表的现代表示学习方法，最后延伸至生成模型与机器人应用，构建了一个完整的知识体系。

---

## 二、计算机视觉概述与应用场景

1. 行业应用热度
	课程展示了中国计算机视觉在不同行业的投融资热度，排名前三的领域为：
	- 零售（64.4%）
	- 安防（50.7%）
	- 制造（47.3%）
	其他如政务、医疗、金融等也占有重要比例，显示出计算机视觉技术的广泛应用前景。
2. 典型应用案例
	- 人脸识别：北大“刷脸入校”系统，实现无卡通行；
	- 视频监控分析：人体属性识别、行人重识别、人群计数；
	- 图像生成与篡改检测：DeepFake、人脸属性编辑；
	- 自动驾驶：道路识别、速度估计、环境感知；
	- 增强现实：如AR试鞋、Google Goggles等。

---
## 三、计算机视觉的基础问题与方法演进

1. 视觉表示理论（David Marr）
	- 原始图像 → 初级草图 → 2.5维草图 → 三维模型
	- 强调从像素到语义的层次化表示过程。
2. 语义鸿沟
	- “语义鸿沟”是针对计算机在识别图像中是否包含某个具体物件上遭遇的问题提出的概念。
	- 计算机所见的低层特征（像素、边缘）与人类理解的高层语义之间存在巨大差异。即对于计算机，从简单的图像特征如像素中提取其表示的“语义特征”(Semantics)是低效率的。
	- 解决方法：引入特征工程与表示学习。
3. 视觉变化与识别粒度
	- 影响因素：姿态、光照、尺度等；
	- 识别任务从粗粒度（是否存在物体）到细粒度（如不同种类的杜鹃鸟）。

---
## 四、经典方法：视觉词袋模型

1. 基本思想
	“词袋模型”源于文本处理领域，即通过不考虑语法和顺序特征，仅考虑文本中词语的集合，视觉处理中借用这一方法提出“视觉词袋模型”（ag-of-Visual-Words, BoVW），核心为将图像视为一系列局部特征的集合，忽略空间关系，构建视觉词典。
	- **局部特征集合**：图像不再被视为像素矩阵，而是被分解为一系列独立的小块。
	- **忽略空间关系**：模型在构建特征时，故意忽略这些局部特征在图像中的空间位置关系。
	- **构建视觉词典**：通过对大量局部特征进行聚类，将相似的特征归为一类，形成一个视觉词典。
2. 流程步骤
	$\text{BoVW}$ 模型通常遵循以下四个主要步骤：

| 步骤           | 核心任务                   | 具体技术（示例）                                            |     |
| :----------- | :--------------------- | :-------------------------------------------------- | --- |
| **检测关键点**    | 识别图像中具有辨识度、对变换稳定的点。    | **Harris** 角点、SIFT/SURF 关键点。 |     |
| **提取局部特征**   | 对关键点周围的区域进行量化描述，生成描述符。 | **SIFT** (尺度不变特征变换) 是最常用的描述符。              |     |
| **聚类构建视觉词典** | 将所有训练图像的局部特征进行聚类。      | **K-means** 聚类算法最常用。聚类中心即为“视觉词”。               |     |
| **量化特征**     | 将每个局部特征分配到最近的视觉词典中心。   | 生成图像直方图：统计图像中每个“视觉词”出现的次数，形成最终的图像表示向量。              |     |

3. Harris角点检测
	Harris角点检测是检测关键点的方法之一，它通过分析图像窗口在不同方向上移动时的灰度变化量来识别角点。 该方法的核心是使用图像窗口的变化量以及由特征值 $(\lambda_1, \lambda_2)$ 构成的矩阵来判断区域类型：

| 区域类型     | 特征值 $(\lambda_1, \lambda_2)$ 条件  | 几何解释                              |     |
| :------- | :------------------------------- | :-------------------------------- | --- |
| **平坦区域** | $\lambda_1$ 和 $\lambda_2$ 都很小。   | 窗口在任何方向上移动，灰度变化都不明显。              |     |
| **边缘**   | 一个特征值远大于另一个。                     | 窗口沿着边缘方向移动时灰度变化小，垂直于边缘方向移动时灰度变化大。 |     |
| **角点**   | $\lambda_1$ 和 $\lambda_2$ 都大且相近。 | 窗口在所有方向上移动，灰度变化都很显著。              |     |
|          |                                  |                                   |     |
  
---
## 五、数据驱动方法的兴起
1. 从传统机器学习到深度学习
	- 传统方法：手工设计特征 + 分类器（如SVM）；
	- 深度学习：端到端学习，自动提取多层次特征。
2. 表示学习
	- 特征提取与模型训练融为一体；
	- 层次化表示：低层 → 中层 → 高层特征。
3. 里程碑：ImageNet与AlexNet
- ImageNet：大规模图像数据集，推动视觉识别竞赛（ILSVRC）；
- AlexNet：首次展示深度卷积网络的强大能力，开启深度学习时代。

---

## 六、深度学习与神经网络
1. 网络结构演进
	- LeNet-5 → AlexNet → VGG → GoogleNet → ResNet
		- **VGG**：该网络通过堆叠小尺寸的 $3 \times 3$ 卷积核来加深网络层级，其设计哲学是**模块化**和**深度优先**。
		- **GoogleNet**：引入 **Inception 模块**，通过并行处理不同尺度的卷积核和 $1 \times 1$ 卷积降维，在保证性能的同时显著降低了参数量和计算复杂度。
		- **ResNet**：该网络引入了**残差连接**（Residual Connection）。这一结构允许信息直接跨层传递，有效解决了超深网络的梯度消失和网络退化问题，是深度学习发展史上的关键一步。
	- 网络层数不断增加，错误率持续下降。
	
2. 核心机制：梯度、链式法则与反向传播
	
	网络的训练核心是**反向传播**（Back Propagation）算法，其目的是实现基于**梯度下降**的参数更新。
	
	**梯度**是训练优化的关键，它表示损失函数相对于网络参数（权重和偏置）的变化率，指明了损失函数值增加最快的方向。通过沿着梯度的负方向进行调整，网络参数可以被优化以最小化损失。
	
	反向传播利用**链式法则**（Chain Rule）这一数学工具。链式法则允许我们将对整个复合函数（即整个网络）的求导分解为对每个局部函数（即每一层神经元）的求导，并将结果逐层传递相乘。
	
	该过程分为前向和后向两个阶段：在前向传播中，数据从输入层流向输出层，计算最终的损失值。在关键的后向传播阶段，算法从输出层的损失开始，利用链式法则逐层向输入层逆向进行，精确计算出损失函数对每一层权重参数的梯度。最终，优化器根据计算出的梯度来调整网络权重，完成参数更新。

---

## 七、生成模型：从判别到生成
1. 生成模型类型
	- 自编码器：编码-解码结构，用于特征学习与重建；
	- 变分自编码器：引入隐变量分布，增强生成多样性；
	- 生成对抗网络：判别器与生成器对抗训练；
	- 扩散模型：通过逐步加噪与去噪实现图像生成。
2. 应用场景
	- 图像生成、风格迁移、DeepFake检测、艺术创作等。
---
## 八、机器人学与视觉的结合

- 案例：OpenAI使用机器人手解魔方；[https://openai.com/blog/solving-rubiks-cube/]
- 强调视觉感知在机器人控制、路径规划、环境交互中的关键作用。

---

## 九、课程建议与学习路径
1. 知识结构建议
	- 数学基础：数学分析、线性代数、最优化、凸优化；
	- 计算机基础：数据结构、算法、系统课程；
	- 机器学习：导论、深度学习、强化学习；
	- 视觉与机器人：计算机视觉、图像处理、3D视觉、控制论。
2. 学习建议
	- “AI is electricity”：认识其双面性；
	- 尽早接触前沿课题，培养科研嗅觉；
	- 重视工程实现能力，理论与实践并重。

---

## 十、总结
本课程系统性地梳理了计算机视觉与机器人学中的数据驱动方法，从传统视觉词袋模型到现代深度学习与生成模型，展现了技术演进的脉络。课程不仅覆盖理论基础与核心技术，还强调实际应用与伦理思考，为学习者构建了完整的知识体系与研究视角。

---

讲师联系方式：穆亚东 myd@pku.edu.cn
课程网站：http://www.muyadong.com

---

## AI 协作记录



---

## 引用