# 数据科学面面观-数据科学中的数据准备

## 一、研究背景
机器学习模型在近些年取得了巨大的进步，但2017年至今大模型（如ChatGPT、SAM）的核心结构未显著变化，均基于Transformer结构，机器学习模型发展遇到了瓶颈，性能收益来源从“模型”转向“数据”。

## 二、定义
* **Data-centric LLMs**：构建LLMs过程中，对数据进行系统化工程处理，并分析数据属性对模型的影响。
* **LLMs训练流程**：包含Pre-Training（预训练）和Fine-tuning（微调）（如instruction/alignment tuning）两个核心阶段。

## 三、研究流程

### （一）LLM预训练
* **目标**：获取模型大部分能力。
* **数据特点**：以无监督形式训练大量无标记文本，如互联网、社交媒体、代码等。
* **核心环节**：数据收集 → 数据过滤 → 数据去重 → 数据评估 → 数据调度

#### （1）数据收集
* **常用数据集**：
    * The Pile：825GB，覆盖22个领域，以学术/专业来源为主
    * C4：156GB-2.3TB，Common Crawl的过滤数据
    * Redpajama：5TB，LLaMA数据集来源
* **数据收集来源**：书籍、网页、媒体、学术论文、专业领域数据等

#### （2） 数据过滤（去除低质量数据）
1.  **基于分类器**：用高质量数据训练分类器，识别并过滤低质量数据（例：GPT-3、Glam等）
2.  **基于启发式规则**：依托人类经验/统计规则（例：Bloom、MimiPile等）
3.  **基于Metric**：训练模型并通过指标（如perplexity困惑度）打分（例：CCNet等）

#### （3）数据去重（提升训练稳定性与效率）
1.  **Exact-based**：去除文字形式完全重复的内容
2.  **Fuzzy-based**：去除文字形式近似重复的内容
3.  **Embedding-based**：去除语义近似重复的内容

#### （4）数据配比
* **核心逻辑**：不同LLM的训练数据配比不同，需通过采样调整各领域数据占比，以高效学习丰富信息。
* **（引申：数据对预训练的作用**
    * 数据数量：模型性能取决于“模型参数+数据量+计算量”，LLM能力与数据规模呈对数线性关系。（Scaling laws）
    * 数据质量：高质量数据可打破传统Scaling laws（即少量高质量数据也能实现高性能）。**）**
* **核心方法**：
    1.  **基于统计**：计算源数据集与目标数据集的相似度，依据相似度调整样本权重。
    2.  **基于Proxy Model**：训练Proxy Model得到最优数据配比权重，再通过该权重重采样数据并训练全量LLM，可提升模型性能。

### （二）LLM微调（SFT）
* **Supervised Finetuning (SFT) 目标**：让LLM获得指令跟随能力，与人类意图对齐。
* **Data-centric SFT的核心方向**：
    1.  提升SFT数据数量（数据生成）；
    2.  提升SFT数据质量（数据选择、增强）；
    3.  分析SFT数据质量（数据评估）。
* **微调数据侧流程**：数据生成 → 数据选择 → 数据评估。

#### （1）数据生成
* **数据类型**：
    1.  **Instruction tuning data**：格式为“任务+输入+输出”，目标是让LLM掌握任务并输出匹配输入的信息。
    2.  **Alignment tuning data**：格式为“Instruction数据+人类反馈”，基于人类价值观对LLM输出做主/客观评价。
* **生成方式**：
    * 手工构造：撰写指令、模型回复，但存在成本高、偏差大、多样性低的问题。
    * LLM生成：借助大模型自动生成数据。

#### （2）数据选择
* **核心逻辑**：平衡数据数量与质量。
* **方法 (Low Training Data Instruction Tuning)**：通过“embedding → clustering → sampling → tuning”流程，从全量数据中筛选高质量数据训练模型，减少计算开销。
* **结论**：小部分样本可达到与全量数据相近/更好的效果，但无法完全替代全量数据，需平衡数量与质量。

#### （3）数据调度
* **调度必要性**：除数据配比外，数据出现的顺序也很重要，可避免负迁移和知识遗忘。
* **核心策略**：
    1.  **Multi-task learning**：增强专业化能力，兼顾通用能力；
    2.  **Sequential/mixed sequential training**：增强通用能力，兼顾专业化能力；
    3.  以“难度递增”的形式调度数据，模拟人类学习过程。

### （三）多模态LLM训练
* **预训练目标**：获取不同模态的对齐能力，数据以“图像+文本”为主。
* **预训练数据侧流程**：数据生成 → 数据选择 → 数据评估。

#### （1）数据选择与评估
* **核心方法**：
    1.  大模型评估：基于GPT4V等大模型、微调后的大模型或Metric进行选择与评估；
    2.  CLIP Score评估：基于图像-文本的相似度选择与评估；
    3.  单模态数据评估：基于文本/图像的质量进行选择与评估。
    4.  大模型选择与评估：基于GPT4V、微调后的大模型或Metric；
    5.  Faithfulness评估：基于事实一致性；
    6.  Hallucination评估：基于物体幻觉（生成不存在的物体）。
    7.  基于关键帧的数据选择
        * 核心方法：基于“帧与问题的相似度”提取关键信息，筛选视频关键帧作为数据。
        * 效果：在视频问答基准测试中，关键帧筛选方法（KeyVideoLLM）的性能显著优于均匀帧选择方法。

### （四）多模态LLM微调Survey
* **《A Survey of Multimodal Large Language Model from A Data-centric Perspective》**
    * 总结了多模态数据集，梳理了多模态预训练、微调及对齐的常见方法，给出了数据侧的洞察与未来工作方向。

---

# Data-Centric AI基础设施

## 一、大模型落地与数据的核心地位
1.  **企业大模型落地难点**：
    * 私有数据无法对外输出，通用LLM缺乏企业深度知识，技术门槛高、部署成本大
2.  **数据是AI的新战场**：
    * 数据准备环节占AI全流程90%工作量，存在格式不规范、数量不足、质量低等问题
    * 需通过标准化数据工具平台降低门槛、控制成本

## 二、数据全流程基础设施
1.  **核心工具链**：
    * **DataFlow**：负责数据准备（解析、合成、处理、评估），支持多模态数据（文档/图像/视频等）
    * **AI数据库**：存储含统计/语义信息的高质量标准化数据
    * **DataFlex**：实现数据动态调度、在线推荐、抽取与配比
    * **MinerU**：1.2B参数的文档解析工具，支持公式/表格/流程图解析，性能超越GPT-4o等模型，应用于书生大模型训练
2.  **数据-算力协同**：
    * 大数据侧：通过Extended SQL、AI数据库支撑数据管理；
    * 大算力侧：依托TensorFlow、CUDA生态提供计算能力。

## 三、数据治理与模型训练的自动化工具
1.  **DataFlow-Agent：对话驱动的数据工程**
    * 能力：自动编排Pipeline、生成数据处理算子、自定义任务链
    * 场景：支持Pipeline推荐/修改、算子编写/优化、数据采集等需求
2.  **数据-模型交互训练系统（DataFlex）**
    * 框架：检查点滞后式动态训练，边训练边评估/采样数据
    * 对接Llama Factory：替代原始训练器，实现动态样本选择、数据配比与权重调整

## 四、基于自然语言交互的大模型数据准备系统
* **核心架构**：以“对话即起数据治理Agent”为中心，通过3个Sub-Agent覆盖全流程
    1.  **数据获取Sub-Agent**：自动采集结构化多源数据，配套复杂版面解析工具
    2.  **数据治理Sub-Agent**：执行数据清洗/去重/增强，依托流水线-算子工具
    3.  **数据-训练Sub-Agent**：实现动态数据自适应模型训练，配套数据选择/配比工具
* **目标**：用户通过自然语言交互，自动化完成数据全生命周期任务

## 五、赋能大模型预训练
* 需更短时间（4天完成传统4个月的工作），更少资源（仅用1/10算力），更低门槛（自动数据准备）
* 数据难度差异：训练前期简单数据易抽取，后期长逻辑推理数据处理难度高

## 六、当前研究挑战与方向
1.  大规模异构数据解析
2.  长思维链推理数据合成
3.  多模态数据治理
4.  大规模数据并行处理
5.  大模型数据质量评估
6.  大模型训练中动态数据选择与配比
7.  基于Agent的数据获取与治理
8.  基于Agent的数据质量反馈与优化