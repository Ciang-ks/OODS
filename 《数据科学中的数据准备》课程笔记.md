# 数据科学面面观-数据科学中的数据准备

## 一、研究背景
机器学习模型在近些年取得了巨大的进步，但2017年至今大模型（如ChatGPT、SAM）的核心结构未显著变化，均基于Transformer结构，机器学习模型发展遇到了瓶颈，性能收益来源从“模型”转向“数据”。

## 二、定义
* **Data-centric LLMs**：构建LLMs过程中，对数据进行系统化工程处理，并分析数据属性对模型的影响。
* **LLMs训练流程**：包含Pre-Training（预训练）和Fine-tuning（微调）（如instruction/alignment tuning）两个核心阶段。

## 三、研究流程

### （一）LLM预训练
* 这个阶段以无监督形式训练大量无标记文本，如互联网、社交媒体、代码等，可以获取模型的大部分能力。
* **核心环节**：数据收集 → 数据过滤 → 数据去重 → 数据评估 → 数据调度

#### 数据收集环节：
常用数据集有The Pile、C4、Redpajama等，从书籍、网页、媒体、学术论文、专业领域数据等途径都可以获取。

####  数据过滤环节
即去除低质量数据，主要的方法有：
1.  **基于分类器**：用高质量数据训练分类器，识别并过滤低质量数据（例：GPT-3、Glam等）
2.  **基于启发式规则**：依托人类经验/统计规则（例：Bloom、MimiPile等）
3.  **基于Metric**：训练模型并通过指标（如perplexity困惑度）打分（例：CCNet等）

#### 数据去重环节
即去除重复数据，以免影响数据比例，可以提升训练稳定性与效率，主要有以下几类：
1.  **Exact-based**：去除文字形式完全重复的内容
2.  **Fuzzy-based**：去除文字形式近似重复的内容
3.  **Embedding-based**：去除语义近似重复的内容

#### 数据配比环节
* 不同LLM的训练数据配比不同，通过采样调整各领域数据占比可以高效学习丰富信息。
* 由Scaling laws可知，模型性能取决于“模型参数+数据量+计算量”，LLM能力与数据规模呈对数线性关系。然而高质量数据可打破传统Scaling laws，即少量高质量数据也能实现高性能。
* 调整数据配比的方法有：
    1.  **基于统计**：计算源数据集与目标数据集的相似度，依据相似度调整样本权重。
    2.  **基于Proxy Model**：训练Proxy Model得到最优数据配比权重，再通过该权重重采样数据并训练全量LLM，可提升模型性能。

### （二）LLM微调（SFT）
* 通过提升SFT数据数量、质量以及分析SFT数据质量，让LLM获得指令跟随能力，与人类意图对齐。
* **微调数据侧流程**：数据生成 → 数据选择 → 数据评估。

#### （1）数据生成
* **数据类型**：
    1.  **Instruction tuning data**：格式为“任务+输入+输出”，目标是让LLM掌握任务并输出匹配输入的信息。
    2.  **Alignment tuning data**：格式为“Instruction数据+人类反馈”，基于人类价值观对LLM输出做主/客观评价。
* **生成方式**：
    * 手工构造：撰写指令、模型回复，但存在成本高、偏差大、多样性低的问题。
    * LLM生成：借助大模型自动生成数据。

#### （2）数据选择
* **核心逻辑**：平衡数据数量与质量。
* **方法 (Low Training Data Instruction Tuning)**：通过“embedding → clustering → sampling → tuning”流程，从全量数据中筛选高质量数据训练模型，减少计算开销。
* **结论**：小部分样本可达到与全量数据相近/更好的效果，但无法完全替代全量数据，需要平衡数量与质量。

#### （3）数据调度
* **调度必要性**：除数据配比外，数据出现的顺序也很重要，可避免负迁移和知识遗忘。
* **核心策略**：
    1.  **Multi-task learning**：增强专业化能力，兼顾通用能力；
    2.  **Sequential/mixed sequential training**：增强通用能力，兼顾专业化能力；
    3.  以“难度递增”的形式调度数据，模拟人类学习过程。

### （三）多模态LLM训练
* **预训练目标**：获取不同模态的对齐能力，数据以“图像+文本”为主。
* **预训练数据侧流程**：数据生成 → 数据选择 → 数据评估。

#### （1）数据选择与评估
* **核心方法**：
    1.  大模型评估：基于GPT4V等大模型、微调后的大模型或Metric进行选择与评估；
    2.  CLIP Score评估：基于图像-文本的相似度选择与评估；
    3.  单模态数据评估：基于文本/图像的质量进行选择与评估。
    4.  大模型选择与评估：基于GPT4V、微调后的大模型或Metric；
    5.  Faithfulness评估：基于事实一致性；
    6.  Hallucination评估：基于物体幻觉（生成不存在的物体）。
    7.  基于关键帧的数据选择
        * 基于“帧与问题的相似度”提取关键信息，筛选视频关键帧作为数据。
        * 在视频问答基准测试中，关键帧筛选方法（KeyVideoLLM）的性能显著优于均匀帧选择方法。

### （四）多模态LLM微调Survey
* **《A Survey of Multimodal Large Language Model from A Data-centric Perspective》**
    * 总结了多模态数据集，梳理了多模态预训练、微调及对齐的常见方法，给出了数据侧的洞察与未来工作方向。

---

## 数据科学工具如何辅助Data-Centric AI基础设施

### 一、背景：企业大模型落地难

在企业大模型落地的主要困难体现在**私有数据无法对外输出**，**通用LLM缺乏企业深度知识**以及**技术门槛高、部署成本大**。
其中门槛和成本高的原因是**数据准备太困难**：数据准备环节占AI全流程90%工作量，存在格式不规范、数量不足、质量低等问题。这就体现了数据处理在大模型训练中的重要性。
这启示我们需要**通过标准化数据工具平台降低门槛、控制成本**。

### 二、与大模型相关的基础设施分类

大模型的算法主要都是基于transformer架构。没有太多变化，因而模型的提升主要增长点在**算力和数据**，相关的基础设施建构就显得很重要。算力的基础是GPU及其生态（现今主要有影响力的是CUDA生态，这正是我国被卡脖子的地方），在此之上算力的基础设施（比如TensorFlow）可以让我们以比较低的成本调动GPU的能力；
而数据基础设施底层是**数据库**以及基于数据库的**Extended SQL生态**，还有做大模型**数据准备的工具**如Dataflow。

### 三、团队在这些方面做出的成果

1. **在AI数据库方面**做了开源的大规模结构化+非结构化融合的**MyScale AI数据库**，拓展了SQL，在同一个系统中支持各类异构数据的高效存储和联合查询

2. 在数据准备工具方面做了**DataFlow的系统**，其架构分为三部分：Data Centric 算法支持、数据库支持和系统支持

   -	Data Centric 算法支持方面关键技术突破为**MinerU数据解析工具**，其超越一些顶级多模态大模型和专业OCR工具，实现对公式、流程图、表格等的全面解析，广泛应用于大模型训练。

   -	与TensorFlow相似，**DataFlow**结合各个模块的特点以及各种通用和行业算子，针对任务构建算子组合流水线

   -	在模型训练方面做了**DataFlex数据-模型交互训练系统**，可以在训练的同时动态选择数据，提升检索速度，需更短时间（4天完成传统4个月的工作），更少资源（仅用1/10算力），更低门槛（自动数据准备）实现更好的效果

3. 基于数据治理的目的针对小白做了**Agent for Data**，可以辅助用户写代码、拆解任务等

   - 用户的主要需求为管线推荐、 算子编写、管线Refine、数据获取、算子Refine。

   - 基于此搭建**基于多智能体协同的自动化数据任务处理系统**，覆盖任务拆解 → 工具注册 → 调度执行 → 结果验证 → 整体总结 的完整流程。

   - 管线编排Agent工作流被划分为如下阶段：

     智能体规划：负责引导用户提交需求表单，理解和分解用户的高层意图

     工具注册：负责动态管理和维护可用的RAG工具库，提升算子匹配准确率

     任务分发：负责将分解后的子任务精准派发给执行单元

     智能体执行：负责具体任务的执行，包括代码生成与调用

   - 目前此Agent可以实现对话即数据工程

   - 在产品层面由两个目标：把语料变成AI Ready的数据集、从数据集生成模型

### 四、应用：赋能大模型预训练、后训练、专有知识库、Agent

从多领域原始数据湖（科研、金融、医疗等）中获取数据，经DataFlow进行数据准备，存入AI 数据库，由DataFlex动态调度数据配比，应用于模型的训练中

核心架构：以“对话即起数据治理Agent”为中心，通过3个Sub-Agent覆盖全流程

1.	 数据获取Sub-Agent：自动采集结构化多源数据，配套复杂版面解析工具
2.	 数据治理Sub-Agent：执行数据清洗/去重/增强，依托流水线-算子工具
3.	 数据-训练Sub-Agent：实现动态数据自适应模型训练，配套数据选择/配比工具

从而创建一个自动化的闭环系统，将大模型评估、缺陷分析、数据搜寻和模型更新四个关键环节紧密连接，形成正反馈循环。

### 五、研究问题与挑战

1.	 大规模异构数据解析
2.	 长思维链推理数据合成
3.	 多模态数据治理
4.	 大规模数据并行处理
5.	 大模型数据质量评估
6.	 大模型训练中动态数据选择与配比
7.	 基于Agent的数据获取与治理
8.	 基于Agent的数据质量反馈与优化

