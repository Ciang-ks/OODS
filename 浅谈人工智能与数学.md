*此为北京大学元培学院“数据科学面面观（2025 秋）”课程的笔记与拓展*

**主讲人**：董彬 教授
**授课时间**：2025年9月18日
**整理**：陈双本

---

## 1. 人工智能发展简史

### 1.1 起源与萌芽 (-1956)

- **神话先驱**：早在BC300，《列子·汤问》中记载的**偃师**造人，展现了人类对“不可分辨真假”的仿生智能最早的想象。
- **理论奠基**：
	- **控制论与神经网络 (1940s)**：诺伯特·维纳提出控制论，视大脑为神经元组成的电子网络，确立了AI的物理与生物学基础。
    - **图灵测试 (1950)**：阿兰·图灵将“机器能否思考”这一哲学命题转化为“行为是否可分辨”的数学/计算机科学命题。
- **正式诞生**：1956年**达特茅斯会议**，正式提出“Artificial Intelligence”概念。

### 1.2 寒冬与回暖 (1974-1993)

- **第一次寒冬 (1974-1980)**：    
    - Minsky在1969年从数学上证明了**XOR问题**（单层感知机无法解决异或/非线性分类问题），直接导致学界对神经网络丧失信心。
- **短暂回暖 (1980-1987)**：**专家系统**兴起。
	- 它试图通过硬编码人类规则来模拟智能，但因缺乏学习能力和可拓展性，最终引发了**第二次寒冬 (1987-1993)**。

### 1.3 数学的正名 (1990s)

- **通用函数逼近定理 (Cybenko, 1989)**：证明了多层前馈网络本质上可以逼近任意连续函数（类似高维泰勒展开），确立了其理论上的全能性。
    
- **打破维数灾难 (Barron, 1993)**：证明了神经网络逼近高维函数的误差主要取决于神经元数量，而与输入维度 d 的指数增长无关。这是AI能够处理图像、自然语言等超高维数据的数学根基。

### 1.4 大爆发时代 (2012-Present)

- **转折点**：2012年 **AlexNet** 在ImageNet夺冠，深度学习全面爆发。
- **里程碑技术**：
    - **ResNet (2015)**：通过残差连接解决深层梯度消失，识别率超越人类。
    - **AlphaGo**：结合强化学习与HJB方程，攻克围棋。
    - **生成式AI**：Diffusion Model (2020) 利用随机微分方程生成图像；ChatGPT (2022) 展现通用语言能力。
    - **科学智能**：AlphaFold (2020) 预测蛋白质结构；DeepMind (2025) 获IMO数学金牌。

---
## 2. 人工智能前沿技术体系

### 2.1 机器学习的范式转变

- **定义**：计算机通过数据自动改进算法 Y=f(X)，本质是从无穷维到无穷维的映射。
- **趋势**：从 **Model-Centric** (精调模型结构) 转向 **Data-Centric** (专注于高质量数据的获取与清洗)。
- **三大支柱**：有监督学习 (标签映射)、无监督学习 (结构发现)、强化学习 (序列决策)。

### 2.2 基础大模型 (Foundation Models)

- **统一架构**：**Transformer** 及其核心的 **注意力机制 (Attention)** ，使得处理文本、图像、代码的架构得以统一。
- **训练逻辑**：看似简单的 **Next Token Prediction** (序列预测)，在海量参数下涌现出了逻辑推理能力。

### 2.3 局限与挑战

- **不可解释性**（Black Box）：深度学习缺乏完备的数学理论支撑。
- **可靠性问题**：逻辑推理过程不严谨，存在幻觉，甚至违背物理规律。
- **硬件瓶颈**：GPU算力与深度学习框架的“卡脖子”风险。

---
## 3. 人工智能的影响与变革

### 3.1 替代还是协助？

- **定位**：AI是**拥有无穷算力的协作者 (Co-pilot)**。
- **交互常态化**：从日常闲聊到学术研讨，与AI的交流将成为常态。
    - **效率**：与大模型的高频交互，其知识获取效率可能高于与一般同行的低效交流。
    - **技能**：**提示词工程 (Prompt Engineering)** 将成为关键软技能（如何精准提问）。
### 3.2 教育领域变革

- **课堂引入**：
    - **AI助教**：**Brainiac Buddy (BB)**，提供24/7的个性化辅导与答疑。
    - **北大“问学”**：探索“大班授课 + AI辅助 + 小班研讨”的新模式。
- **大学生应对策略**：
    - **祛魅与利用**：不迷信AI，但能够使用AI作为工具（代码辅助、文献梳理）。
    - **批判性思维**：针对AI的“幻觉”问题，培养核查事实与逻辑纠错的能力。

---
## 4. 展望未来：AI for Math (AI赋能数学)

### 4.1 数学发展的“卡脖子”困境

- **体系复杂**：现代数学分支极度深奥且庞杂（如代数几何与组合数学），人类数学家难以跨领域掌握全部前沿。
- **前沿难题**：复杂证明的验证耗时耗力，超出个体认知极限。

### 4.2 AI的解决方案

- **知识融合**：利用AI的海量记忆与检索，打破学科壁垒，有机融合全领域数学知识。
- **辅助研究**：
    - **自然语言表达**：降低数学门槛，通过对话辅助数学家理解复杂概念。
    - **证实猜想**：生成猜想并进行形式化证明（将自然语言证明转化为计算机可验证的代码）。
- **基础设施建设**：
    - **目标**：建立高质量、标准化的数学类数据库。
    - **产物**：打造数学领域“基础软件” (如Lean, Coq等)，赋能数学学科发展。

---
# *Appendix

---

董彬老师的课程不仅为我们梳理了人工智能的发展脉络，更提出了一个核心矛盾：**高维数学问题的求解难度与人类有限认知能力之间的矛盾**。这恰恰是当下 AI for Science (AI4S) 发展的支点所在。
本部分将尝试给出一些对AI for Math（AI for Science）方面的感想，并基于课程内容提供有关领域的一些拓展信息。

### 1. 突破维数灾难：AI 在科学计算中的本质优势

课程中提到的 Barron (1993) 关于“无维数灾难”的证明，实际上是 AI4S能够成立的基石。在传统科学计算中（如流体力学、量子化学），我们往往依赖网格法。但处理某些高维复杂方程时，这种传统方法的计算量会呈指数级爆炸。

AI 为这一问题提供了全新的思路：**神经算子 (Neural Operators)**。 不同于传统数值方法去求解离散点，深度学习模型会直接学习函数空间之间的映射。而神经网络对高维变量“不敏感”，这使得 AI 能够以比传统方法快 1000 倍甚至 10 万倍的速度求解复杂的物理方程。这种能力让过去无法计算的复杂系统（如全尺度的天气预报 GraphCast，或超大分子的动力学模拟）出现可解的可能。

### 2. “黑盒”与“白盒”的博弈：物理信息神经网络

教授还提到了 AI 容易“违背物理规律”和“缺乏严谨性”。这也是目前AI+Science最激烈的战场——**数据驱动 (Data-Driven) 与 机理驱动 (Physics-Based)**。

传统的深度学习是基于数据的概率拟合（黑盒），它可能生成一张极其逼真的流体图片，但该流体可能完全违背真实物理定律。为了解决这个问题，前沿研究提出**物理信息神经网络 (PINNs)**。 PINNs 的核心思想是将物理方程（如偏微分方程 PDE）作为损失函数的一部分加入到神经网络的训练中。这样，模型不仅是在拟合数据，更是在“受物理定律约束”的解空间中寻找答案。这种**“灰盒”**模式，既利用了神经网络强大的拟合能力，又通过数学方程保证了结果的物理可信度。这完美呼应了课程中关于“数学严谨性”与“深度学习”需要结合的观点。

### 3. AI for Math：从加速器到协作者

长久以来，计算机只是一个能够快速做数值计算的加速器。但现在，随着大模型逻辑推理能力的提升，AI 有机会成为数学前沿科研的协作者。
除了课程中提到的自动定理证明，DeepMind 的 AlphaGeometry 和 AIMO 的进展表明，AI 正在开始具备“直觉”。在解决几何题时，AI 不再是暴力搜索，而是像人类一样学会了“添加辅助线”。这种“直觉”的涌现，或许意味着 AI 正在触及数学创造力的边缘。

### 4. 结语

我们正处于科学发现范式转移的风暴眼：第一范式是实验科学（记录现象），第二范式是理论科学（牛顿定律），第三范式是计算科学（模拟），而现在我们正进入全新范式——**数据密集型科学发现**。
未来的科研，可能不再是单纯地推导公式或做实验，而是设计更好的算法架构，学习自然界海量数据背后的高维流形。未来的发展圣杯，不仅仅是训练更大的模型，更要去**完善深度学习的数学理论**，打开这个“黑盒”，让 AI 真正成为人类探索未知边界的可靠伙伴。

**"AI for Math, Math for AI."**

---

- *整理该笔记的过程中使用了AI工具：Google Gemini3 Pro参与协助了Markdown格式的改进，并为课程板块拓展提供了检索和整理上的便利。*